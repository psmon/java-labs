runby = "unittest -Dconfig.resource=/dev.conf"

my-dispatcher-test1 {
    # Dispatcher is the name of the event-based dispatcher
    type = Dispatcher
    # What kind of ExecutionService to use
    executor = "fork-join-executor"
    # Configuration for the fork join pool
    fork-join-executor {
        # Min number of threads to cap factor-based parallelism number to
        parallelism-min = 2
        # Parallelism (threads) ... ceil(available processors * factor)
        parallelism-factor = 2.0
        # Max number of threads to cap factor-based parallelism number to
        parallelism-max = 50
    }
    # Throughput defines the maximum number of messages to be
    # processed per actor before the thread jumps to the next actor.
    # Set to 1 for as fair as possible.
    throughput = 10
}

my-dispatcher-streamtest {
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    fixed-pool-size = 50
  }
  throughput = 1
}

akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  stdout-loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {
     default-dispatcher {
        # ThreadPool의 최소 크기
        fork-join-executor.parallelism-min = 10

        # ThreadPool의 최대 크기
        fork-join-executor.parallelism-max = 50

        # ThreadPool의 기준 크기
        fork-join-executor.parallelism-factor = 2.0
    }
  }
}

# Properties for akka.kafka.ProducerSettings can be
# defined in this section or a configuration section with
# the same layout.
akka.kafka.producer {
  # Config path of Akka Discovery method
  # "akka.discovery" to use the Akka Discovery method configured for the ActorSystem
  discovery-method = akka.discovery

  # Set a service name for use with Akka Discovery
  # https://doc.akka.io/docs/alpakka-kafka/current/discovery.html
  service-name = ""

  # Timeout for getting a reply from the discovery-method lookup
  resolve-timeout = 3 seconds

  # Tuning parameter of how many sends that can run in parallel.
  # In 2.0.0: changed the default from 100 to 10000
  parallelism = 10000

  # Duration to wait for `KafkaProducer.close` to finish.
  close-timeout = 60s

  # Call `KafkaProducer.close` when the stream is shutdown. This is important to override to false
  # when the producer instance is shared across multiple producer stages.
  close-on-producer-stop = true

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the producer stages. Some blocking may occur.
  # When this value is empty, the dispatcher configured for the stream
  # will be used.
  use-dispatcher = "akka.kafka.default-dispatcher"

  # The time interval to commit a transaction when using the `Transactional.sink` or `Transactional.flow`
  # for exactly-once-semantics processing.
  eos-commit-interval = 100ms

  # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
  # can be defined in this configuration section.
  kafka-clients {
  }
}

akka.kafka.consumer {

  enable.auto.commit = true

  kafka-clients {
    bootstrap.servers = "localhost:9092"
  }
}

akka.kafka.committer {

  # Maximum number of messages in a single commit batch
  max-batch = 1000

  # Maximum interval between commits
  max-interval = 3s

  # Parallelsim for async committing
  parallelism = 100

  # API may change.
  # Delivery of commits to the internal actor
  # WaitForAck: Expect replies for commits, and backpressure the stream if replies do not arrive.
  # SendAndForget: Send off commits to the internal actor without expecting replies (experimental feature since 1.1)
  delivery = WaitForAck

  # API may change.
  # Controls when a `Committable` message is queued to be committed.
  # OffsetFirstObserved: When the offset of a message has been successfully produced.
  # NextOffsetObserved: When the next offset is observed.
  when = OffsetFirstObserved
}

alpakka.s3 {
  # whether the buffer request chunks (up to 5MB each) to "memory" or "disk"
  buffer = "memory"

  # location for temporary files, if buffer is set to "disk". If empty, uses the standard java temp path.
  disk-buffer-path = ""

  # An address of a proxy that will be used for all connections using HTTP CONNECT tunnel.
  # forward-proxy {
  #   scheme = "https"
  #   host = "proxy"
  #   port = 8080
  #   credentials {
  #     username = "username"
  #     password = "password"
  #   }
  # }

  # default values for AWS configuration
  aws {
    # If this section is absent, the fallback behavior is
    # to use the same configuration as if credentials.provider = default
    credentials {
      # anonymous requests (no auth)
      #
      # provider = anon

      # static credentials
      #
      # provider = static
      access-key-id = "test"
      secret-access-key = "test"
      # token = "" # optional

      # default: as described in software.amazon.awssdk.auth.credentials.DefaultCredentialsProvider docs,
      # attempts to get the credentials from either:
      #   - environment variables
      #   - system properties
      #   - credentials file
      #   - EC2 credentials service
      #   - IAM / metadata
      provider = default
    }

    # If this section is absent, the fallback behavior is
    # to use the same configuration as if region.provider = default
    region {
      # static credentials
      #
      # provider = static
      #
      # This can be set to the `id` value of any of the regions defined in
      # software.amazon.awssdk.regions.Region
      default-region = "us-east-1"

      # default: as described in software.amazon.awssdk.regions.providers.DefaultAwsRegionProviderChain docs,
      # attempts to get the region from either:
      #   - environment variables
      #   - system properties
      #   - progile file
      #   - EC2 metadata
      provider = default
    }
  }

  # DEPRECATED (since Alpakka 2.0.0)
  # AWS S3 is going to retire path-style access, thus prefer the virtual-host-style access
  # https://aws.amazon.com/blogs/aws/amazon-s3-path-deprecation-plan-the-rest-of-the-story/
  #
  # Also, prefer to use the newer access-style property.
  #
  # Possible values:
  #  - false: use virtual-host style access
  #  - true: use legacy path-style access, warnings will be logged
  #  - force: use legacy path-style access, disable warnings
  #  - empty, null or absent (default): use `access-style`, which in turn defaults to virtual-host style access
  # path-style-access = false

  # Which access style to use. Prefer to use this setting over path-style-access.
  # Path-style access has been deprecated by Amazon and will not work on buckets created after September 30, 2020.
  # For alternative S3 implementations (MinIO, Rados Gateway, etc.), path-style access may continue to be required.
  # Possible values:
  #  - virtual: virtual host-style access, i.e. https://<bucket name>.s3.amazonaws.com/file/inside/bucket
  #  - path: path-style access, i.e. https://<region>.amazonaws.com/<bucket>/file/inside/bucket
  access-style = virtual

  # Custom endpoint url, used for alternate s3 implementations
  # To enable virtual-host-style access with Alpakka S3 use the placeholder `{bucket}` in the URL
  # eg. endpoint-url = "http://{bucket}.s3minio.alpakka:9000"
  #
  endpoint-url = "http://my-test-bucket.localhost:4567"

  # Which version of the list bucket api to use. Set to 1 to use the old style version 1 API.
  # By default the newer version 2 api is used.
  list-bucket-api-version = 2

  # Object keys are validated to NOT use sub-directory selection with `..` to improve security.
  # This flag may disable the validation.
  # See https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMetadata.html
  validate-object-key = true

  # Default settings corresponding to automatic retry of requests in an S3 stream.
  retry-settings {
    # The maximum number of additional attempts (following transient errors) that will be made to process a given
    # request before giving up.
    max-retries = 3

    # The minimum delay between request retries.
    min-backoff = 200ms

    # The maximum delay between request retries.
    max-backoff = 10s

    # Random jitter factor applied to retry delay calculation.
    random-factor = 0.0
  }

  # Settings specific to S3 multipart uploads.
  multipart-upload {

    retry-settings = ${alpakka.s3.retry-settings}
  }

  # Add signature headers to requests when aws.credentials.provider is anon
  sign-anonymous-requests = true
}